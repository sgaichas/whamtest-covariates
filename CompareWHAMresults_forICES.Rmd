---
title: "Compare WHAM results"
author: "Sarah Gaichas, Micah Dean, Jon Deroba"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# ICES Title and Abstract

## Fit for the future? Environmental covariates and random effects in stock assessment

Considerable effort has been invested in evaluating potential environmental drivers of stock productivity, mortality, and/or availability in recent Northwest Atlantic stock assessments. Additional recent investment in regional ocean modeling is aimed at operational short term prediction of environmental conditions such as bottom temperature. Environmental drivers have been successfully included in stock assessments using the Woods Hole Assessment Model (WHAM), a state-space modeling framework. Here we review lessons learned and controversial opinions generated from attempts to include environmental recruitment covariates within a stock assessment for Atlantic herring. Environmental covariates were tailored to herring life history and implemented based on mechanistic hypotheses. Despite significant correlations with recruitment estimated from a prior (non-state-space) assessment model, none of the covariates were included in the final state-space model. We draw two main conclusions. First, even in a state of the art model there are limits on environmental covariate inclusion. For example, mechanistic linkages available for recruitment covariates dwindle if a stock recruit relationship cannot be estimated. Second, tradeoffs may exist between including mechanistic drivers as covariates and including random effects that account for variation from unidentified mechanisms. Herring recruitment covariates had much stronger explanatory power in the absence of numbers at age (NAA) random effects, but model fit was much better with NAA random effects. Given that some environmental covariates can be forecast, while some random effects cannot or it is not clear how, this presents a dilemma. Do we risk sacrificing short term prediction capability (needed by management) for assessment model fit (needed to get models accepted for use in management)? 

## ICES keywords

State space models, recruitment prediction, stock assessment, ecological indicators


# Introduction

Here we are looking at different WHAM assessment configurations with and without environmental covariates (ecov) and numbers at age random effects (NAA RE). 

This work will be presented at the 2025 ICES Annual Science Conference. We are speaking in the "Controversial opinions in stock assessment and fisheries management session. The submitted abstract outlines the presentation.

In this document we will work out the code for comparing models with different configurations and develop visualizations for the presentation. 

# Methods

## Compare models

This code follows that posted in the WHAM model vignettes https://timjmiller.github.io/wham/articles/ex02_CPI_recruitment.html 

We are using Atlantic herring assessment models developed for the 2025 Research Track assessment that have already been run and are stored locally.  Some were rerun using the script in this repository (https://github.com/sgaichas/whamtest-covariates/blob/main/Tests.R) to get a full set for comparison. 

We'll focus on the haddock predation models but can use similar code to read in the models evaluating temperature covariates.

First read in the stored model outputs and name them. Then make a list object of models for comparison.

We can compare models with and without NAA RE estimated as long as the input data is the same. So the base model can't be compared (ecov not included) but the other four can, and the NAAon_ecovoff model *should* be identical to base in all practical ways. Base is staying in the nix to ensure that is true.

```{r}

# keep the object names (base etc) and just sub in the temperature model directories if needed

base <- readRDS(here::here("WHAMfits/mm192_meanrecpar_4Feb25/mm192_meanrecpar_4Feb25.rds"))

NAAon_ecovoff <- readRDS(here::here("WHAMfits/mm204-ecovoff/mm204-ecovoff.rds"))

NAAon_ecovon <- readRDS(here::here("WHAMfits/mm205-test/mm205-test.rds"))

NAAoff_ecovoff <- readRDS(here::here("WHAMfits/mm206-ecovoff/mm206-ecovoff.rds"))

NAAoff_ecovon <- readRDS(here::here("WHAMfits/mm207-ecovon/mm207-ecovon.rds"))

mods <- list(base = base, 
             NAAon_ecovoff = NAAon_ecovoff, 
             NAAon_ecovon = NAAon_ecovon, 
             NAAoff_ecovoff = NAAoff_ecovoff, 
             NAAoff_ecovon = NAAoff_ecovon)

n.mods <- length(mods)
```

Make a table with names, setup, convergence, etc

```{r}
df.mods <- data.frame(Model = names(mods),
                      NAA_re_sigma = unlist(unname(lapply(mods, function(x) x$input$options$NAA_re$sigma))),
                      NAA_re_cor = unlist(unname(lapply(mods, function(x) x$input$options$NAA_re$cor))),
                      recruit_model = unlist(unname(lapply(mods, function(x) x$input$data$recruit_model))),
                      Ecov_how_R =  unlist(unname(lapply(mods, function(x) x$input$data$Ecov_how_R))),
                      n_poly_Ecov_R = unlist(unname(lapply(mods, function(x) x$input$data$n_poly_Ecov_R))),
                      Ecov_model =  names(unlist(unname(lapply(mods, function(x) x$input$data$Ecov_model)))),
                      Ecov_obs_sigma_opt =  unlist(unname(lapply(mods, function(x) x$input$data$Ecov_obs_sigma_opt))))

df.mods$Ecov_lag_R  <- ifelse(df.mods$Ecov_model %in% c("rw", "ar1"), unlist(unname(lapply(mods, function(x) which(x$input$years_Ecov==tail(x$input$years,1)) - x$input$data$ind_Ecov_out_end_R - 1))), "")

# end model year
#tail(x$input$years,1)

# lag
#which(x$input$years_Ecov==tail(x$input$years,1)) - x$input$data$ind_Ecov_out_end_R - 1

# use words
df.mods$recruit_model <- dplyr::case_match(df.mods$recruit_model, 1 ~ "Random walk", 2 ~ "Random about mean", 3 ~ "Bev-Holt", 4 ~ "Ricker")
df.mods$Ecov_how_R <- dplyr::case_match(df.mods$Ecov_how_R, 0 ~ "none", 1 ~ "controlling", 2 ~ "limiting", 3 ~ "lethal", 4 ~ "masking", 5 ~ "directive")
df.mods$n_poly_Ecov_R <- ifelse(df.mods$n_poly_Ecov_R == 1, "linear", paste0("polynomial-", df.mods$n_poly_Ecov_R))
df.mods$Ecov_obs_sigma_opt <- dplyr::case_match(df.mods$Ecov_obs_sigma_opt, 1~ "", 2 ~ "est_1", 4 ~ "est_re")

# reduce confusion about the base model
df.mods$Ecov_how_R <- ifelse(df.mods$Model == "base", "", df.mods$Ecov_how_R)
df.mods$n_poly_Ecov_R <- ifelse(df.mods$Model == "base", "", df.mods$n_poly_Ecov_R)


# get diagnostics
opt_conv = 1-sapply(mods, function(x) x$opt$convergence)
ok_sdrep = sapply(mods, function(x) if(x$na_sdrep==FALSE & !is.na(x$na_sdrep)) 1 else 0)
df.mods$conv <- as.logical(opt_conv)
df.mods$pdHess <- as.logical(ok_sdrep)
df.mods$NLL <- sapply(mods, function(x) round(x$opt$objective,3))

not_conv <- !df.mods$conv | !df.mods$pdHess
mods2 <- mods
mods2[not_conv] <- NULL

# take out the base model for final comparison
mods2 <- mods2[-1]

df.aic.tmp <- as.data.frame(wham::compare_wham_models(mods2, table.opts=list(sort=FALSE, calc.rho=T, print=F))$tab)
df.aic <- df.aic.tmp[FALSE,]
ct = 1
for(i in 1:n.mods){
  if(not_conv[i]){
    df.aic[i,] <- rep(NA,5)
  } else {
    df.aic[i,] <- df.aic.tmp[ct,]
    ct <- ct + 1
  }
}
df.aic <- tibble::rownames_to_column(df.aic)

df.mods <- dplyr::left_join(df.mods, df.aic, dplyr::join_by(Model == rowname))
df.mods <- df.mods[order(df.mods$dAIC, na.last=TRUE),]
df.mods[is.na(df.mods$AIC), c('dAIC','AIC','rho_R','rho_SSB','rho_Fbar')] <- "---"
rownames(df.mods) <- NULL

diagonly <- df.mods |>
  dplyr::select(Model, conv, pdHess, NLL, dAIC, AIC, rho_R, rho_SSB, rho_Fbar)

flextable::flextable(diagonly)
  


```

For kicks we can see that the base model has the same retrospective diagnostics as the NAAon-ecovoff model, as expected.

```{r}
basediag <- as.data.frame(wham::compare_wham_models(mods[1], table.opts=list(sort=FALSE, calc.rho=T, print=F))$tab)

flextable::flextable(basediag)

```

The models without NAA RE clearly fit more poorly than those with. 

We can see the WHAM comparison outputs of the ecov models by running this

```{r}
wham::compare_wham_models(mods2, do.table = F)
```




## Visualizations

We get max 8 slides to describe this rather complex work so streamline the visualization.

## Title slide (cheating not counting this)

Controversial opinion/conclusion: 

Both random effects and environmental covariates can help explain modeled population dynamics, but they may interact in unexpected ways. 

RE represent cumulative unknown drivers, which can be difficult to project into the future without understanding mechanisms, while environmental covariates represent possibly predictable but incomplete mechanistic drivers, whose influence may change over time.

RE solve a lot of diagnostic issues in models (e.g. retrospective patterns) and are considerably easier to implement than environmental covariates, which require considerable investment in research and development.

Do we risk sacrificing short term prediction capability (needed by management) for assessment model fit (needed to get models accepted for use in management)? 

## Slide 1

Intro: goal was develop a new state space herring assessment and explore with ecological covariates

Map of herring stock we are talking about

History and current status

## Slide 2

Possible ecological drivers: haddock predation

Micah's spatial modeling and index development

High inverse correlation of resulting haddock index with previously estimated herring recruitment

## Slide 3

New state space model developed with NAA RE, best fit with numbers at age transition correlations among ages but not years

Image of NAA RE pattern

Good model diagnostics

## Slide 4

Including the covariate in the model: only one approach possible because stock recruit relationship not estimable

Model estimates recruitment as annual iid RE around an estimated fixed effect recruitment scaling parameter ("mean-ish" recruitment)

Model estimates a fit to covariate data, then estimates parameters of relationship with recruitment scaling parameter (lag-1-linear)

Image of fit to haddock predation index covariate

## Slide 5

Given correlation with previous recruitment estimates, it was surprising how little impact the covariate had on recruitment or the full models

Side by side image of rec scaling parameter estimate with and without the covariate

Didn't substantially improve model fit or reduce the process SD for recruitment, and the slope estimate CI included 0

## Slide 6

An experiment fitting the model without NAA RE on older ages and with the environmental covariate resulted in poorer model fit but a much stronger covariate effect

And a different recruitment time series? NAA RE on ages soaking up some uncertainty that could be explained mechanistically

Image comparing recruitment deviations with and without NAA RE and impact of haddock predation index 

## Slide 7

But which mechanism? We got a similar effect with a different environmental covariate--optimal larval temperature. Try to include both??

And maybe its just herring's NAA RE? Yellowtail assessment had both NAA RE and an influential environmental covariate included. 

Image of larval temp covariate with and without NAA RE, image of Yellowtail fit if I can get it?

## Conclusion

RE interactions with covariates in state space assessment models obviously needs more investigation

We tend to obsess about historical model fit, then do projections separately with a single best fit model, but projections are the thing used in management for catch advice

Past performance does not guarantee future returns!

